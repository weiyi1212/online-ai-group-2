{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1645407866514,
     "user": {
      "displayName": "CH D",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08014395801573999343"
     },
     "user_tz": -480
    },
    "id": "QJQbSyhBzAQa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "random.seed(5483)\n",
    "import numpy as np\n",
    "np.random.seed(5483)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2344,
     "status": "ok",
     "timestamp": 1645407868854,
     "user": {
      "displayName": "CH D",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08014395801573999343"
     },
     "user_tz": -480
    },
    "id": "iT3RE_gAzUIr"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/training_set/log_mini.csv', dtype={'skip_1':int, 'skip_2':int, 'skip_3':int, 'not_skipped':int, 'hist_user_behavior_is_shuffle':int, 'premium':int})\n",
    "tf = pd.read_csv('data/track_features/tf_mini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2454,
     "status": "ok",
     "timestamp": 1645407871304,
     "user": {
      "displayName": "CH D",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08014395801573999343"
     },
     "user_tz": -480
    },
    "id": "oZyIRcFYKkCR"
   },
   "outputs": [],
   "source": [
    "cols_to_select = [\n",
    "    'context_switch',\n",
    "    'context_type',\n",
    "    'hist_user_behavior_is_shuffle',\n",
    "    'hist_user_behavior_n_seekback',\n",
    "    'hist_user_behavior_n_seekfwd',\n",
    "    'hist_user_behavior_reason_end',\n",
    "    'hist_user_behavior_reason_start',\n",
    "    'hour_of_day',\n",
    "    'long_pause_before_play',\n",
    "    'no_pause_before_play',\n",
    "    'not_skipped',\n",
    "    'premium',\n",
    "    'session_position',\n",
    "    'short_pause_before_play',\n",
    "    'skip_1',\n",
    "    'skip_2',\n",
    "    'skip_3',\n",
    "    'dayofweek']\n",
    "cols_tf = ['duration', 'release_year', 'us_popularity_estimate',\n",
    "       'acousticness', 'beat_strength', 'bounciness', 'danceability',\n",
    "       'dyn_range_mean', 'energy', 'flatness', 'instrumentalness', 'key',\n",
    "       'liveness', 'loudness', 'mechanism', 'organism', 'speechiness',\n",
    "       'tempo', 'time_signature', 'valence', 'acoustic_vector_0',\n",
    "       'acoustic_vector_1', 'acoustic_vector_2', 'acoustic_vector_3',\n",
    "       'acoustic_vector_4', 'acoustic_vector_5', 'acoustic_vector_6',\n",
    "       'acoustic_vector_7']\n",
    "cols_log = ['session_id', 'session_position', 'session_length', 'track_id_clean',\n",
    "       'skip_1', 'skip_2', 'skip_3', 'not_skipped', 'context_switch',\n",
    "       'no_pause_before_play', 'short_pause_before_play',\n",
    "       'long_pause_before_play', 'hist_user_behavior_n_seekfwd',\n",
    "       'hist_user_behavior_n_seekback', 'hist_user_behavior_is_shuffle',\n",
    "       'hour_of_day', 'date', 'premium', 'context_type',\n",
    "       'hist_user_behavior_reason_start', 'hist_user_behavior_reason_end',\n",
    "       'dayofweek']\n",
    "data_df = df.loc[lambda x: x.session_length==20]\n",
    "log_features = data_df.loc[lambda x: x.session_position <= (x.session_length/2)].copy()\n",
    "log_features.date = pd.to_datetime(log_features.date)\n",
    "log_features['dayofweek'] = log_features.date.dt.dayofweek\n",
    "replace_idx = log_features.hist_user_behavior_reason_start.isin(['endplay', 'popup', 'uriopen', 'clickside']).copy()\n",
    "log_features.loc[replace_idx, 'hist_user_behavior_reason_start'] = 'replaced'\n",
    "replace_idx = log_features.hist_user_behavior_reason_end.isin(['clickrow', 'appload', 'popup', 'uriopen', 'clickside', 'logout']).copy()\n",
    "log_features.loc[replace_idx, 'hist_user_behavior_reason_end'] = 'replaced'\n",
    "tf.rename(columns={'track_id': 'track_id_clean'}, inplace=True)\n",
    "features = pd.merge(log_features, tf, on=['track_id_clean'], how='inner')\n",
    "features.sort_values(['session_id', 'session_position'], inplace=True)\n",
    "features.reset_index(drop=True, inplace=True)\n",
    "ground_truth = data_df.loc[lambda x: x.session_position > (x.session_length/2)].loc[:, ['session_id', 'session_position', 'session_length', 'track_id_clean', 'skip_2']].copy()\n",
    "ground_truth.sort_values(['session_id', 'session_position'], inplace=True)\n",
    "ground_truth.reset_index(drop=True, inplace=True)\n",
    "pred_y = np.array(ground_truth.groupby('session_id')['skip_2'].apply(lambda x: x.tolist()).tolist())\n",
    "\n",
    "feats_dummies = pd.get_dummies(features.loc[:, cols_to_select])\n",
    "feats_track = features.loc[:, cols_tf]\n",
    "all_seq = np.array(features.reset_index().groupby('session_id')['index'].apply(lambda x: x.tolist()).tolist())\n",
    "y_seq = np.array(features.reset_index().groupby('session_id')['skip_2'].apply(lambda x: x.tolist()).tolist())[:, -1:]\n",
    "all_seq = np.concatenate((all_seq, y_seq), axis=1)\n",
    "cols_order = sorted(feats_dummies.columns.values)\n",
    "log_mat = feats_dummies.loc[:, cols_order].values\n",
    "track_mat = feats_track.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_seq, pred_y, test_size=0.2, random_state=5483)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 7389,
     "status": "ok",
     "timestamp": 1645407878689,
     "user": {
      "displayName": "CH D",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08014395801573999343"
     },
     "user_tz": -480
    },
    "id": "x1tAw-yElx_q"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, BatchNormalization, Input, Dense, LSTM, concatenate, Bidirectional, RepeatVector, Dropout, Lambda\n",
    "import keras.backend as K\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1645407878690,
     "user": {
      "displayName": "CH D",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08014395801573999343"
     },
     "user_tz": -480
    },
    "id": "ru9ytND4LJKt"
   },
   "outputs": [],
   "source": [
    "def model_net(log_mat, track_mat):\n",
    "  seq_input = Input(shape=(None,), name='log_input')\n",
    "  log_embed = Embedding(input_dim=log_mat.shape[0], output_dim=log_mat.shape[1], weights=[log_mat], trainable=False, mask_zero=False, name='session_embed')\n",
    "  track_embed = Embedding(input_dim=track_mat.shape[0], output_dim=track_mat.shape[1], weights=[track_mat],trainable=False,mask_zero=False,name='track_embed')\n",
    "  log_bn = BatchNormalization(name='bn1')\n",
    "  log_transformer = Dense(64, activation='relu', name='session_transformer')\n",
    "  x1 = log_embed(seq_input)\n",
    "  x1 = log_bn(x1)\n",
    "  x1 = log_transformer(x1)\n",
    "  track_bn = BatchNormalization(name='track_bn')\n",
    "  track_transformer = Dense(64, activation='relu', name='track_transformer')\n",
    "  x2 = track_embed(seq_input)\n",
    "  x2 = track_bn(x2)\n",
    "  x2 = track_transformer(x2)\n",
    "  x = concatenate([x1, x2], axis=-1)\n",
    "  x = Bidirectional(LSTM(64, return_sequences=False, return_state=False), name='lstm1')(x)\n",
    "  x = RepeatVector(1)(x)\n",
    "  x_en = Dense(256, activation='relu', name='base_transformer')(x)\n",
    "  _, fwd_sh, fwd_sc, bck_sh, bck_sc = Bidirectional(LSTM(256, return_sequences=False, return_state=True))(x_en)\n",
    "  fwd_sh = Dropout(0.2)(fwd_sh)\n",
    "  fwd_sc = Dropout(0.2)(fwd_sc)\n",
    "  bck_sh = Dropout(0.2)(bck_sh)\n",
    "  bck_sc = Dropout(0.2)(bck_sc)\n",
    "  y_p = Input(shape=(1, 1), name='y_seq')\n",
    "  all_ouputs = []\n",
    "  decoder_2 = Bidirectional(LSTM(256, return_sequences=True, return_state=True, name='decoder_2'))\n",
    "  decoder_3 = LSTM(64, return_sequences=True, return_state=True, name='decoder_3')\n",
    "  decoder_4 = Dropout(0.3)\n",
    "  decoder_5 = Dense(1, activation='sigmoid', name='decoder_5')\n",
    "  x = concatenate([x_en, y_p])\n",
    "  x, fwd_sh, fwd_sc, bck_sh, bck_sc = decoder_2(x, initial_state=[fwd_sh, fwd_sc, bck_sh, bck_sc])\n",
    "  x, sh, sc = decoder_3(x)\n",
    "  x = decoder_4(x)\n",
    "  out = decoder_5(x)\n",
    "  all_ouputs.append(out)\n",
    "\n",
    "  for i in range(1, 10):\n",
    "    x = concatenate([x_en, out])\n",
    "    x, fwd_sh, fwd_sc, bck_sh, bck_sc = decoder_2(x, initial_state=[fwd_sh, fwd_sc, bck_sh, bck_sc])\n",
    "    x, sh, sc = decoder_3(x)\n",
    "    x = decoder_4(x)\n",
    "    out = decoder_5(x)\n",
    "    all_ouputs.append(out)\n",
    "  out_combined = Lambda(lambda x: K.concatenate(x, axis=1))(all_ouputs)\n",
    "  model = Model(inputs=[seq_input, y_p], outputs=[out_combined])\n",
    "  model.compile(optimizer=adam_v2.Adam(lr=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22825,
     "status": "ok",
     "timestamp": 1645407901501,
     "user": {
      "displayName": "CH D",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08014395801573999343"
     },
     "user_tz": -480
    },
    "id": "r5vTeTJFY5F_",
    "outputId": "21bc6164-d729-4396-c8b0-b03d458f3d15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " log_input (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " session_embed (Embedding)      (None, None, 36)     1823760     ['log_input[0][0]']              \n",
      "                                                                                                  \n",
      " track_embed (Embedding)        (None, None, 28)     1418480     ['log_input[0][0]']              \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)       (None, None, 36)     144         ['session_embed[0][0]']          \n",
      "                                                                                                  \n",
      " track_bn (BatchNormalization)  (None, None, 28)     112         ['track_embed[0][0]']            \n",
      "                                                                                                  \n",
      " session_transformer (Dense)    (None, None, 64)     2368        ['bn1[0][0]']                    \n",
      "                                                                                                  \n",
      " track_transformer (Dense)      (None, None, 64)     1856        ['track_bn[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, None, 128)    0           ['session_transformer[0][0]',    \n",
      "                                                                  'track_transformer[0][0]']      \n",
      "                                                                                                  \n",
      " lstm1 (Bidirectional)          (None, 128)          98816       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 1, 128)       0           ['lstm1[0][0]']                  \n",
      "                                                                                                  \n",
      " base_transformer (Dense)       (None, 1, 256)       33024       ['repeat_vector[0][0]']          \n",
      "                                                                                                  \n",
      " y_seq (InputLayer)             [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  [(None, 512),        1050624     ['base_transformer[0][0]']       \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1, 257)       0           ['base_transformer[0][0]',       \n",
      "                                                                  'y_seq[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['bidirectional[0][1]']          \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 256)          0           ['bidirectional[0][2]']          \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 256)          0           ['bidirectional[0][3]']          \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 256)          0           ['bidirectional[0][4]']          \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  [(None, 1, 512),    1052672     ['concatenate_1[0][0]',          \n",
      " )                               (None, 256),                     'dropout[0][0]',                \n",
      "                                 (None, 256),                     'dropout_1[0][0]',              \n",
      "                                 (None, 256),                     'dropout_2[0][0]',              \n",
      "                                 (None, 256)]                     'dropout_3[0][0]',              \n",
      "                                                                  'concatenate_2[0][0]',          \n",
      "                                                                  'bidirectional_1[0][1]',        \n",
      "                                                                  'bidirectional_1[0][2]',        \n",
      "                                                                  'bidirectional_1[0][3]',        \n",
      "                                                                  'bidirectional_1[0][4]',        \n",
      "                                                                  'concatenate_3[0][0]',          \n",
      "                                                                  'bidirectional_1[1][1]',        \n",
      "                                                                  'bidirectional_1[1][2]',        \n",
      "                                                                  'bidirectional_1[1][3]',        \n",
      "                                                                  'bidirectional_1[1][4]',        \n",
      "                                                                  'concatenate_4[0][0]',          \n",
      "                                                                  'bidirectional_1[2][1]',        \n",
      "                                                                  'bidirectional_1[2][2]',        \n",
      "                                                                  'bidirectional_1[2][3]',        \n",
      "                                                                  'bidirectional_1[2][4]',        \n",
      "                                                                  'concatenate_5[0][0]',          \n",
      "                                                                  'bidirectional_1[3][1]',        \n",
      "                                                                  'bidirectional_1[3][2]',        \n",
      "                                                                  'bidirectional_1[3][3]',        \n",
      "                                                                  'bidirectional_1[3][4]',        \n",
      "                                                                  'concatenate_6[0][0]',          \n",
      "                                                                  'bidirectional_1[4][1]',        \n",
      "                                                                  'bidirectional_1[4][2]',        \n",
      "                                                                  'bidirectional_1[4][3]',        \n",
      "                                                                  'bidirectional_1[4][4]',        \n",
      "                                                                  'concatenate_7[0][0]',          \n",
      "                                                                  'bidirectional_1[5][1]',        \n",
      "                                                                  'bidirectional_1[5][2]',        \n",
      "                                                                  'bidirectional_1[5][3]',        \n",
      "                                                                  'bidirectional_1[5][4]',        \n",
      "                                                                  'concatenate_8[0][0]',          \n",
      "                                                                  'bidirectional_1[6][1]',        \n",
      "                                                                  'bidirectional_1[6][2]',        \n",
      "                                                                  'bidirectional_1[6][3]',        \n",
      "                                                                  'bidirectional_1[6][4]',        \n",
      "                                                                  'concatenate_9[0][0]',          \n",
      "                                                                  'bidirectional_1[7][1]',        \n",
      "                                                                  'bidirectional_1[7][2]',        \n",
      "                                                                  'bidirectional_1[7][3]',        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'bidirectional_1[7][4]',        \n",
      "                                                                  'concatenate_10[0][0]',         \n",
      "                                                                  'bidirectional_1[8][1]',        \n",
      "                                                                  'bidirectional_1[8][2]',        \n",
      "                                                                  'bidirectional_1[8][3]',        \n",
      "                                                                  'bidirectional_1[8][4]']        \n",
      "                                                                                                  \n",
      " decoder_3 (LSTM)               [(None, 1, 64),      147712      ['bidirectional_1[0][0]',        \n",
      "                                 (None, 64),                      'bidirectional_1[1][0]',        \n",
      "                                 (None, 64)]                      'bidirectional_1[2][0]',        \n",
      "                                                                  'bidirectional_1[3][0]',        \n",
      "                                                                  'bidirectional_1[4][0]',        \n",
      "                                                                  'bidirectional_1[5][0]',        \n",
      "                                                                  'bidirectional_1[6][0]',        \n",
      "                                                                  'bidirectional_1[7][0]',        \n",
      "                                                                  'bidirectional_1[8][0]',        \n",
      "                                                                  'bidirectional_1[9][0]']        \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 1, 64)        0           ['decoder_3[0][0]',              \n",
      "                                                                  'decoder_3[1][0]',              \n",
      "                                                                  'decoder_3[2][0]',              \n",
      "                                                                  'decoder_3[3][0]',              \n",
      "                                                                  'decoder_3[4][0]',              \n",
      "                                                                  'decoder_3[5][0]',              \n",
      "                                                                  'decoder_3[6][0]',              \n",
      "                                                                  'decoder_3[7][0]',              \n",
      "                                                                  'decoder_3[8][0]',              \n",
      "                                                                  'decoder_3[9][0]']              \n",
      "                                                                                                  \n",
      " decoder_5 (Dense)              (None, 1, 1)         65          ['dropout_4[0][0]',              \n",
      "                                                                  'dropout_4[1][0]',              \n",
      "                                                                  'dropout_4[2][0]',              \n",
      "                                                                  'dropout_4[3][0]',              \n",
      "                                                                  'dropout_4[4][0]',              \n",
      "                                                                  'dropout_4[5][0]',              \n",
      "                                                                  'dropout_4[6][0]',              \n",
      "                                                                  'dropout_4[7][0]',              \n",
      "                                                                  'dropout_4[8][0]',              \n",
      "                                                                  'dropout_4[9][0]']              \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 1, 257)       0           ['base_transformer[0][0]',       \n",
      "                                                                  'decoder_5[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 1, 257)       0           ['base_transformer[0][0]',       \n",
      "                                                                  'decoder_5[1][0]']              \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 1, 257)       0           ['base_transformer[0][0]',       \n",
      "                                                                  'decoder_5[2][0]']              \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 1, 257)       0           ['base_transformer[0][0]',       \n",
      "                                                                  'decoder_5[3][0]']              \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 1, 257)       0           ['base_transformer[0][0]',       \n",
      "                                                                  'decoder_5[4][0]']              \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 1, 257)       0           ['base_transformer[0][0]',       \n",
      "                                                                  'decoder_5[5][0]']              \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 1, 257)       0           ['base_transformer[0][0]',       \n",
      "                                                                  'decoder_5[6][0]']              \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 1, 257)       0           ['base_transformer[0][0]',       \n",
      "                                                                  'decoder_5[7][0]']              \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 1, 257)       0           ['base_transformer[0][0]',       \n",
      "                                                                  'decoder_5[8][0]']              \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 10, 1)        0           ['decoder_5[0][0]',              \n",
      "                                                                  'decoder_5[1][0]',              \n",
      "                                                                  'decoder_5[2][0]',              \n",
      "                                                                  'decoder_5[3][0]',              \n",
      "                                                                  'decoder_5[4][0]',              \n",
      "                                                                  'decoder_5[5][0]',              \n",
      "                                                                  'decoder_5[6][0]',              \n",
      "                                                                  'decoder_5[7][0]',              \n",
      "                                                                  'decoder_5[8][0]',              \n",
      "                                                                  'decoder_5[9][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,629,633\n",
      "Trainable params: 2,387,265\n",
      "Non-trainable params: 3,242,368\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_net(log_mat, track_mat)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1645407901502,
     "user": {
      "displayName": "CH D",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08014395801573999343"
     },
     "user_tz": -480
    },
    "id": "vqPYCNI84wrV",
    "outputId": "e3e9fe49-5194-45b3-c2ab-7eaed523f2de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss',\n",
    "                     patience=15,\n",
    "                     verbose=1,\n",
    "                     min_delta=1e-4,\n",
    "                     mode='min'),\n",
    "    ReduceLROnPlateau(monitor='val_loss',\n",
    "                         factor=0.1,\n",
    "                         patience=4,\n",
    "                         verbose=1,\n",
    "                         epsilon=1e-4,\n",
    "                         mode='min'),\n",
    "    ModelCheckpoint(monitor='val_loss',\n",
    "                       filepath='model_weights_best.h5',\n",
    "                       save_best_only=True,\n",
    "                       save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 177879,
     "status": "ok",
     "timestamp": 1645408079366,
     "user": {
      "displayName": "CH D",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08014395801573999343"
     },
     "user_tz": -480
    },
    "id": "h13fyyvV4m43",
    "outputId": "439bb123-9a35-40fc-f95b-17713db0abf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 81s 635ms/step - loss: 0.6920 - accuracy: 0.5500 - val_loss: 0.6904 - val_accuracy: 0.5559 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 4s 122ms/step - loss: 0.6458 - accuracy: 0.6383 - val_loss: 0.6858 - val_accuracy: 0.5744 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 3s 116ms/step - loss: 0.6328 - accuracy: 0.6687 - val_loss: 0.6864 - val_accuracy: 0.5559 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 3s 121ms/step - loss: 0.6264 - accuracy: 0.6740 - val_loss: 0.6775 - val_accuracy: 0.5766 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 4s 126ms/step - loss: 0.6195 - accuracy: 0.6777 - val_loss: 0.6881 - val_accuracy: 0.5584 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 3s 118ms/step - loss: 0.6148 - accuracy: 0.6854 - val_loss: 0.6899 - val_accuracy: 0.5704 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 3s 118ms/step - loss: 0.6113 - accuracy: 0.6883 - val_loss: 0.6854 - val_accuracy: 0.5842 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 4s 131ms/step - loss: 0.6056 - accuracy: 0.6967 - val_loss: 0.6658 - val_accuracy: 0.6232 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 3s 116ms/step - loss: 0.6027 - accuracy: 0.6970 - val_loss: 0.7179 - val_accuracy: 0.4475 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 4s 147ms/step - loss: 0.6025 - accuracy: 0.6984 - val_loss: 0.6406 - val_accuracy: 0.6310 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 3s 117ms/step - loss: 0.5971 - accuracy: 0.7015 - val_loss: 0.6850 - val_accuracy: 0.5315 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 3s 119ms/step - loss: 0.5938 - accuracy: 0.7074 - val_loss: 0.6319 - val_accuracy: 0.6382 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 3s 116ms/step - loss: 0.5858 - accuracy: 0.7148 - val_loss: 0.6485 - val_accuracy: 0.6143 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 4s 133ms/step - loss: 0.5844 - accuracy: 0.7183 - val_loss: 0.6190 - val_accuracy: 0.6680 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 3s 117ms/step - loss: 0.5743 - accuracy: 0.7264 - val_loss: 0.6272 - val_accuracy: 0.6579 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 3s 119ms/step - loss: 0.5774 - accuracy: 0.7224 - val_loss: 0.6227 - val_accuracy: 0.6719 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 3s 117ms/step - loss: 0.5690 - accuracy: 0.7305 - val_loss: 0.6288 - val_accuracy: 0.6665 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.5647 - accuracy: 0.7355\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "29/29 [==============================] - 3s 116ms/step - loss: 0.5647 - accuracy: 0.7355 - val_loss: 0.6317 - val_accuracy: 0.6734 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 3s 117ms/step - loss: 0.5528 - accuracy: 0.7422 - val_loss: 0.6305 - val_accuracy: 0.6690 - lr: 1.0000e-03\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 3s 118ms/step - loss: 0.5428 - accuracy: 0.7521 - val_loss: 0.6328 - val_accuracy: 0.6744 - lr: 1.0000e-03\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 3s 115ms/step - loss: 0.5353 - accuracy: 0.7577 - val_loss: 0.6372 - val_accuracy: 0.6751 - lr: 1.0000e-03\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.5326 - accuracy: 0.7629\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "29/29 [==============================] - 3s 116ms/step - loss: 0.5326 - accuracy: 0.7629 - val_loss: 0.6355 - val_accuracy: 0.6729 - lr: 1.0000e-03\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 3s 116ms/step - loss: 0.5273 - accuracy: 0.7634 - val_loss: 0.6372 - val_accuracy: 0.6734 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 3s 116ms/step - loss: 0.5276 - accuracy: 0.7659 - val_loss: 0.6388 - val_accuracy: 0.6692 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 3s 115ms/step - loss: 0.5265 - accuracy: 0.7653 - val_loss: 0.6398 - val_accuracy: 0.6682 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.5252 - accuracy: 0.7656\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "29/29 [==============================] - 3s 115ms/step - loss: 0.5252 - accuracy: 0.7656 - val_loss: 0.6410 - val_accuracy: 0.6685 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 3s 115ms/step - loss: 0.5250 - accuracy: 0.7648 - val_loss: 0.6409 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 3s 115ms/step - loss: 0.5254 - accuracy: 0.7650 - val_loss: 0.6409 - val_accuracy: 0.6690 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 3s 116ms/step - loss: 0.5239 - accuracy: 0.7664 - val_loss: 0.6410 - val_accuracy: 0.6687 - lr: 1.0000e-05\n",
      "Epoch 29: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3fc8e0a7d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=[X_train[:, :-1], X_train[:, -1:]], \n",
    "    y=y_train, \n",
    "    batch_size=128, \n",
    "    epochs=100, \n",
    "    verbose=1, \n",
    "    callbacks=callbacks, \n",
    "    validation_split=0.1, \n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2665,
     "status": "ok",
     "timestamp": 1645408082362,
     "user": {
      "displayName": "CH D",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08014395801573999343"
     },
     "user_tz": -480
    },
    "id": "Aldwimr1NdFR",
    "outputId": "3eee821d-4729-4233-cf93-62ed5cdcf015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 37ms/step - loss: 0.6167 - accuracy: 0.6751\n",
      "Test Loss:0.616710364818573.\n",
      "Test Accuracy:0.6751479506492615.\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('model_weights_best.h5')\n",
    "loss, acc = model.evaluate(\n",
    "    x=[X_test[:, :-1], X_test[:, -1:]], \n",
    "    y=y_test\n",
    ")\n",
    "print('Test Loss:{}.\\nTest Accuracy:{}.'.format(loss, acc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO0m1v/LA+R1RglugMa6+RT",
   "collapsed_sections": [],
   "name": "project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
